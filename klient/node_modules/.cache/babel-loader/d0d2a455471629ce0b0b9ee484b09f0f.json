{"ast":null,"code":"'use strict';\n\nexports.__esModule = true;\nexports.tokenize = exports.test = exports.scanner = exports.parser = exports.options = exports.inherits = exports.find = undefined;\n\nvar _class = require('./linkify/utils/class');\n\nvar _options = require('./linkify/utils/options');\n\nvar options = _interopRequireWildcard(_options);\n\nvar _scanner = require('./linkify/core/scanner');\n\nvar scanner = _interopRequireWildcard(_scanner);\n\nvar _parser = require('./linkify/core/parser');\n\nvar parser = _interopRequireWildcard(_parser);\n\nfunction _interopRequireWildcard(obj) {\n  if (obj && obj.__esModule) {\n    return obj;\n  } else {\n    var newObj = {};\n\n    if (obj != null) {\n      for (var key in obj) {\n        if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key];\n      }\n    }\n\n    newObj.default = obj;\n    return newObj;\n  }\n}\n\nif (!Array.isArray) {\n  Array.isArray = function (arg) {\n    return Object.prototype.toString.call(arg) === '[object Array]';\n  };\n}\n/**\n\tConverts a string into tokens that represent linkable and non-linkable bits\n\t@method tokenize\n\t@param {String} str\n\t@return {Array} tokens\n*/\n\n\nvar tokenize = function tokenize(str) {\n  return parser.run(scanner.run(str));\n};\n/**\n\tReturns a list of linkable items in the given string.\n*/\n\n\nvar find = function find(str) {\n  var type = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n  var tokens = tokenize(str);\n  var filtered = [];\n\n  for (var i = 0; i < tokens.length; i++) {\n    var token = tokens[i];\n\n    if (token.isLink && (!type || token.type === type)) {\n      filtered.push(token.toObject());\n    }\n  }\n\n  return filtered;\n};\n/**\n\tIs the given string valid linkable text of some sort\n\tNote that this does not trim the text for you.\n\n\tOptionally pass in a second `type` param, which is the type of link to test\n\tfor.\n\n\tFor example,\n\n\t\ttest(str, 'email');\n\n\tWill return `true` if str is a valid email.\n*/\n\n\nvar test = function test(str) {\n  var type = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n  var tokens = tokenize(str);\n  return tokens.length === 1 && tokens[0].isLink && (!type || tokens[0].type === type);\n}; // Scanner and parser provide states and tokens for the lexicographic stage\n// (will be used to add additional link types)\n\n\nexports.find = find;\nexports.inherits = _class.inherits;\nexports.options = options;\nexports.parser = parser;\nexports.scanner = scanner;\nexports.test = test;\nexports.tokenize = tokenize;","map":null,"metadata":{},"sourceType":"script"}